{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbaaeec4",
   "metadata": {},
   "source": [
    "Start your qdrant server first (or use the free qdrant SAAS tier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5046e668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of embeddings: <class 'list'>\n",
      "Number of embeddings: 1\n",
      "Embedding dimension: 3072\n",
      "First 5 values: [-0.024923978373408318, 0.014082803390920162, -0.020037217065691948, -0.0819728896021843, 0.011573716066777706]\n"
     ]
    }
   ],
   "source": [
    "# Initialize clients\n",
    "\n",
    "\n",
    "MODEL_ID = \"gemini-embedding-001\"\n",
    "\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "vertexai.init(project=\"focused-beacon-460816-f6\", location=\"us-central1\")\n",
    "\n",
    "model = TextEmbeddingModel.from_pretrained(MODEL_ID)\n",
    "embeddings = model.get_embeddings([\"Hello world! This is a test embedding.\"])\n",
    "\n",
    "# Print the embedding object to see its structure\n",
    "print(f\"Type of embeddings: {type(embeddings)}\")\n",
    "print(f\"Number of embeddings: {len(embeddings)}\")\n",
    "\n",
    "# Extract the first embedding's values and check its dimensionality\n",
    "first_embedding = embeddings[0]\n",
    "embedding_values = first_embedding.values\n",
    "print(f\"Embedding dimension: {len(embedding_values)}\")\n",
    "\n",
    "# Print a sample of the values (first 5 elements)\n",
    "print(f\"First 5 values: {embedding_values[:5]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f02c6138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a local qdrant DB\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "\n",
    "# qdrant = QdrantClient(path=\"../qdrant\")  # Persists changes to disk (no qdrant UI though)\n",
    "\n",
    "qdrant = QdrantClient(\"http://localhost:6333\") # Connect to existing Qdrant instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69fd6727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "# Define collection name as a variable\n",
    "collection_name = \"GendergerechteSprache-Gemini-Embedding-001\"\n",
    "\n",
    "# Check if collection exists and create it if it doesn't\n",
    "if qdrant.collection_exists(collection_name=collection_name):\n",
    "    qdrant.delete_collection(collection_name=collection_name)\n",
    "qdrant.create_collection(\n",
    "    collection_name=collection_name, # Cluster centroids\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE))  # Gemini embedding size is 768\n",
    "\n",
    "demo_sentences = [\"Gesucht: IT-Berater:in\",\n",
    "                  \"Gesucht: IT-Berater\",\n",
    "                  \"Gesucht: IT-Consultant\",\n",
    "                  \"Gesucht: IT-Beraterin\",\n",
    "                  \"Gesucht: IT-Berater*in\",\n",
    "                  \"Gesucht: IT-Beratende\",\n",
    "                  \"Gesucht: Bademeister\",\n",
    "                  \"Gesucht: Bademeisterin\",\n",
    "                  \"Gesucht: Bademeister*in\",\n",
    "                  \"Gesucht: Bademeister:in\",\n",
    "                  \"Gesucht: Hufschmied\",\n",
    "                  \"Gesucht: Hufschmiedin\",\n",
    "                  \"Gesucht: Hufschmied:in\",\n",
    "                  \"Gesucht: Hufschmied*in\"\n",
    "                  ] \n",
    "\n",
    "# Use Google Vertex AI (Gemini) for embeddings\n",
    "for i, sentence in enumerate(demo_sentences, start=200):\n",
    "    # Get embedding using Vertex AI Gemini model\n",
    "    embeddings = model.get_embeddings([sentence])\n",
    "    emb = embeddings[0].values\n",
    "    \n",
    "    # Add the sentence and its embedding to qdrant\n",
    "    qdrant.upsert(\n",
    "    collection_name=collection_name,\n",
    "        points=[\n",
    "            PointStruct(\n",
    "                id=i,\n",
    "                vector=emb,\n",
    "                payload={\"sentence\": sentence}\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "qdrant.count(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0630e7",
   "metadata": {},
   "source": [
    "Take a look at http://localhost:6333/dashboard\n",
    "\n",
    "Wit a visualisation config such as this one:\n",
    "```\n",
    "{\n",
    "  \"limit\": 500,\n",
    "  \"algorithm\": \"UMAP\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f7f586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'Gesucht: IT-Berater'\n",
      "\n",
      "Results (ordered by similarity):\n",
      "--------------------------------------------------\n",
      "• Gesucht: IT-Berater\n",
      "  Similarity: 0.0000 (0.00%)\n",
      "\n",
      "• Gesucht: IT-Berater:in\n",
      "  Similarity: 0.0386 (3.86%)\n",
      "\n",
      "• Gesucht: IT-Berater*in\n",
      "  Similarity: 0.0392 (3.92%)\n",
      "\n",
      "• Gesucht: IT-Beratende\n",
      "  Similarity: 0.0482 (4.82%)\n",
      "\n",
      "• Gesucht: IT-Beraterin\n",
      "  Similarity: 0.0503 (5.03%)\n",
      "\n",
      "• Gesucht: IT-Consultant\n",
      "  Similarity: 0.1068 (10.68%)\n",
      "\n",
      "• Gesucht: Bademeister\n",
      "  Similarity: 0.3134 (31.34%)\n",
      "\n",
      "• Gesucht: Bademeister:in\n",
      "  Similarity: 0.3151 (31.51%)\n",
      "\n",
      "• Gesucht: Bademeister*in\n",
      "  Similarity: 0.3191 (31.91%)\n",
      "\n",
      "• Gesucht: Hufschmied:in\n",
      "  Similarity: 0.3229 (32.29%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query qdrant with the sentence \"Gesucht: IT-Berater\", print the results and their cosine similarity\n",
    "# Get embedding for the query sentence using Vertex AI Gemini\n",
    "query_sentence = \"Gesucht: IT-Berater\"\n",
    "embeddings = model.get_embeddings([query_sentence])\n",
    "query_vector = embeddings[0].values\n",
    "\n",
    "# Search for similar sentences in the collection\n",
    "search_results = qdrant.search(\n",
    "    collection_name=collection_name,\n",
    "    query_vector=query_vector,\n",
    "    limit=10  # Return top 10 results\n",
    ")\n",
    "\n",
    "# Print the results with their cosine similarity scores\n",
    "print(f\"Query: '{query_sentence}'\\n\")\n",
    "print(\"Results (ordered by similarity):\")\n",
    "print(\"-\" * 50)\n",
    "for result in search_results:\n",
    "    # Cosine similarity score (higher is more similar)\n",
    "    similarity = 1 - result.score  # Converting from distance to similarity\n",
    "    percentage = similarity * 100\n",
    "    \n",
    "    print(f\"• {result.payload['sentence']}\")\n",
    "    print(f\"  Similarity: {similarity:.4f} ({percentage:.2f}%)\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
